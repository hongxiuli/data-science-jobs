{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f8abcfc-6884-4100-a48e-cfe3d89edf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bba146f2-c4b8-4ec7-aae3-99b36a0f6e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 9\n",
    "\n",
    "def sigmoid(x, with_noise=True):\n",
    "    sig = 1 / (1 + np.exp(-x))\n",
    "    if(with_noise):\n",
    "        return sig + np.random.uniform(0,0.1, len(x))\n",
    "    return sig\n",
    "\n",
    "def sample_one_data(l, with_noise=True):\n",
    "    start= -4.5\n",
    "    x = np.linspace(start, start + l, l, False) \n",
    "    t = x + np.random.uniform(-0.1, 0.1, len(x))\n",
    "    sigs = sigmoid(t, with_noise)\n",
    "    return t, sigs\n",
    "\n",
    "def sample_data(batch_size, l, with_noise=True):\n",
    "    result = np.empty((batch_size, l))\n",
    "    for i in range(batch_size):\n",
    "        result[i,:] = sample_one_data(l, with_noise)[1]\n",
    "    return result[:,:-1].reshape((batch_size, l-1, 1)), result[:, -1:]\n",
    "\n",
    "class MyGenerator(Sequence):\n",
    "    def __init__(self, batch_size=200, batch_num = MAX_SEQ_LEN - 1, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_num = batch_num\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        # generate the samples\n",
    "        self.batch_data = {}\n",
    "        for i in range(2, 2+batch_num):\n",
    "            X, y = sample_data(batch_size, i, with_noise=False)\n",
    "            self.batch_data[i] = (X, y)\n",
    "            \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return self.batch_num\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.__data_generation(index)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Shuffles indexes after each epoch'\n",
    "        self.indexes = np.arange(self.batch_num)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, index):\n",
    "        X, y = self.batch_data[index+2]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae1b7e4a-8c9b-48d6-a544-1169a6b49fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load existing model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, None, 10)          480       \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 5)                 320       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 806\n",
      "Trainable params: 806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_cp_path = 'model/lstm_sigmoid.hdf5'\n",
    "def create_model():\n",
    "    if(os.path.isfile(model_cp_path)):\n",
    "       print(\"load existing model\")\n",
    "       model = load_model(model_cp_path)\n",
    "       print(model.summary())\n",
    "       return model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, input_shape=(None, 1), return_sequences=True))\n",
    "    model.add(LSTM(5, input_shape=(None, 1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "                      \n",
    "cp = ModelCheckpoint(\n",
    "    filepath = model_cp_path,\n",
    "    monitor = 'loss',\n",
    "    mode = 'min',\n",
    "    save_best_only=True)\n",
    "es = EarlyStopping(monitor='loss', patience=50)\n",
    "def train_model(model):\n",
    "    train_data = MyGenerator(batch_size = 90)\n",
    "    val_data = MyGenerator(batch_size = 10)\n",
    "    model.fit(\n",
    "        train_data,\n",
    "        validation_data = val_data,\n",
    "        epochs = 500,\n",
    "        callbacks=[cp, es])\n",
    "model = create_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbaa8c8-379f-4e10-9204-eb758a93619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb34c49f-a9cb-4fb7-b473-687c392b57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(batch_size, l):\n",
    "    testX, testY = sample_data(batch_size, l, with_noise=False)\n",
    "    print(testX)\n",
    "    yhat = model.predict(testX)\n",
    "    print((yhat-testY)/testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bbc71a9-eebc-4f33-9f13-79ca19c4e1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.01174852]\n",
      "  [0.02773328]\n",
      "  [0.07146586]\n",
      "  [0.18935028]\n",
      "  [0.38594487]\n",
      "  [0.60926625]\n",
      "  [0.80328379]]\n",
      "\n",
      " [[0.01139348]\n",
      "  [0.02702191]\n",
      "  [0.07827758]\n",
      "  [0.17314163]\n",
      "  [0.37621499]\n",
      "  [0.63238909]\n",
      "  [0.80668449]]\n",
      "\n",
      " [[0.01007294]\n",
      "  [0.02836821]\n",
      "  [0.0825333 ]\n",
      "  [0.18834553]\n",
      "  [0.36823949]\n",
      "  [0.64273416]\n",
      "  [0.81286598]]\n",
      "\n",
      " [[0.01186893]\n",
      "  [0.0270533 ]\n",
      "  [0.08169694]\n",
      "  [0.19538236]\n",
      "  [0.37531956]\n",
      "  [0.64177073]\n",
      "  [0.82280018]]]\n",
      "[[-0.00221594]\n",
      " [ 0.00739721]\n",
      " [ 0.0004099 ]\n",
      " [ 0.00184962]]\n"
     ]
    }
   ],
   "source": [
    "test_model(4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1516275-ba42-4850-b8fd-d53ab2a678fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_iter(batch_size, start_l):\n",
    "    testX, target = sample_data(batch_size, MAX_SEQ_LEN, with_noise=False)\n",
    "    print(testX)\n",
    "    # start from the first start_l seq:\n",
    "    testX = testX[:, :start_l-1]\n",
    "    l = start_l - 1\n",
    "    while(l < MAX_SEQ_LEN):\n",
    "        print(\"evaluate textX:\")\n",
    "        print(testX)\n",
    "        yhat = model.predict(testX)\n",
    "        testX = np.concatenate((testX.reshape((batch_size, l)), yhat), axis=1)\n",
    "        l += 1\n",
    "       \n",
    "    print((yhat-target)/target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc629eaf-e443-45f7-ad4b-e93f9611f8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.01154905]\n",
      "  [0.02788961]\n",
      "  [0.08139759]\n",
      "  [0.18598707]\n",
      "  [0.38596484]\n",
      "  [0.6188432 ]\n",
      "  [0.81786093]\n",
      "  [0.9209393 ]]\n",
      "\n",
      " [[0.01079502]\n",
      "  [0.03080518]\n",
      "  [0.0746893 ]\n",
      "  [0.18596632]\n",
      "  [0.39374002]\n",
      "  [0.61978698]\n",
      "  [0.83101648]\n",
      "  [0.92166735]]\n",
      "\n",
      " [[0.01052324]\n",
      "  [0.03137689]\n",
      "  [0.06994062]\n",
      "  [0.18308916]\n",
      "  [0.37470314]\n",
      "  [0.63747598]\n",
      "  [0.82552157]\n",
      "  [0.9235981 ]]\n",
      "\n",
      " [[0.01078883]\n",
      "  [0.02795538]\n",
      "  [0.08054654]\n",
      "  [0.17055414]\n",
      "  [0.3919028 ]\n",
      "  [0.62882056]\n",
      "  [0.80706729]\n",
      "  [0.91740551]]]\n",
      "evaluate textX:\n",
      "[[[0.01154905]\n",
      "  [0.02788961]\n",
      "  [0.08139759]]\n",
      "\n",
      " [[0.01079502]\n",
      "  [0.03080518]\n",
      "  [0.0746893 ]]\n",
      "\n",
      " [[0.01052324]\n",
      "  [0.03137689]\n",
      "  [0.06994062]]\n",
      "\n",
      " [[0.01078883]\n",
      "  [0.02795538]\n",
      "  [0.08054654]]]\n",
      "evaluate textX:\n",
      "[[0.01154905 0.02788961 0.08139759 0.18080011]\n",
      " [0.01079502 0.03080518 0.0746893  0.18074781]\n",
      " [0.01052324 0.03137689 0.06994062 0.18069509]\n",
      " [0.01078883 0.02795538 0.08054654 0.18071991]]\n",
      "evaluate textX:\n",
      "[[0.01154905 0.02788961 0.08139759 0.18080011 0.37802315]\n",
      " [0.01079502 0.03080518 0.0746893  0.18074781 0.37790954]\n",
      " [0.01052324 0.03137689 0.06994062 0.18069509 0.37780625]\n",
      " [0.01078883 0.02795538 0.08054654 0.18071991 0.37788349]]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4c383823a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "evaluate textX:\n",
      "[[0.01154905 0.02788961 0.08139759 0.18080011 0.37802315 0.62146688]\n",
      " [0.01079502 0.03080518 0.0746893  0.18074781 0.37790954 0.62131631]\n",
      " [0.01052324 0.03137689 0.06994062 0.18069509 0.37780625 0.62120062]\n",
      " [0.01078883 0.02795538 0.08054654 0.18071991 0.37788349 0.62133163]]\n",
      "evaluate textX:\n",
      "[[0.01154905 0.02788961 0.08139759 0.18080011 0.37802315 0.62146688\n",
      "  0.81794137]\n",
      " [0.01079502 0.03080518 0.0746893  0.18074781 0.37790954 0.62131631\n",
      "  0.81782436]\n",
      " [0.01052324 0.03137689 0.06994062 0.18069509 0.37780625 0.62120062\n",
      "  0.81774151]\n",
      " [0.01078883 0.02795538 0.08054654 0.18071991 0.37788349 0.62133163\n",
      "  0.81785202]]\n",
      "evaluate textX:\n",
      "[[0.01154905 0.02788961 0.08139759 0.18080011 0.37802315 0.62146688\n",
      "  0.81794137 0.92434609]\n",
      " [0.01079502 0.03080518 0.0746893  0.18074781 0.37790954 0.62131631\n",
      "  0.81782436 0.92428827]\n",
      " [0.01052324 0.03137689 0.06994062 0.18069509 0.37780625 0.62120062\n",
      "  0.81774151 0.92424762]\n",
      " [0.01078883 0.02795538 0.08054654 0.18071991 0.37788349 0.62133163\n",
      "  0.81785202 0.92430264]]\n",
      "[[ 0.00252727]\n",
      " [ 0.00147257]\n",
      " [-0.00229239]\n",
      " [-0.00208235]]\n"
     ]
    }
   ],
   "source": [
    "test_model_iter(4, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
